AWSTemplateFormatVersion: '2010-09-09'
Description: Company data managmement
Resources:

# Recreate Default VPC
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: EC2AccessRole
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - ec2:*
              Resource: "*"
            - Effect: Allow
              Action:
              - logs:*
              Resource: "*"

  InitFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import json
          import boto3
          import threading
          import urllib3
          SUCCESS = "SUCCESS"
          FAILED = "FAILED"
          http = urllib3.PoolManager()
          def send(event, context, responseStatus, responseData, physicalResourceId=None, noEcho=False, reason=None):
              responseUrl = event['ResponseURL']
              print(responseUrl)
              responseBody = {}
              responseBody['Status'] = responseStatus
              responseBody['Reason'] = reason or "See the details in CloudWatch Log Stream: {}".format(context.log_stream_name)
              responseBody['PhysicalResourceId'] = physicalResourceId or context.log_stream_name
              responseBody['StackId'] = event['StackId']
              responseBody['RequestId'] = event['RequestId']
              responseBody['LogicalResourceId'] = event['LogicalResourceId']
              responseBody['NoEcho'] = noEcho
              responseBody['Data'] = responseData
              json_responseBody = json.dumps(responseBody)
              print("Response body:\n" + json_responseBody)
              headers = {
                  'content-type' : '',
                  'content-length' : str(len(json_responseBody))
              }
              try:
                  response = http.request('PUT',responseUrl,headers=headers,body=json_responseBody)
                  print("Status code: {}".format(str(response.status)))
              except Exception as e:
                  print("send(..) failed executing requests.put(..): " + str(e))
          def createDefault():
              print("Creating default VPC")
              ec2 = boto3.client('ec2')
              response = ec2.create_default_vpc()
              return response
          def deleteDefault():
              return ""
          def timeout(event, context):
              print('Timing out, sending failure response to CFN')
              send(event, context, FAILED, {}, None)
          def lambda_handler(event, context):
              print(f'Received event: {json.dumps(event)}')
              timer = threading.Timer((context.get_remaining_time_in_millis() / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              status = SUCCESS
              responseData = {}
              try:
                  if event['RequestType'] == 'Delete':
                      deleteDefault()
                  else:
                      response = createDefault()
                      print(response)
                      responseData['Data'] = response
              except Exception as e:
                  print(e)
                  status = FAILED
              finally:
                  timer.cancel()
                  send(event, context, status, responseData, None)
      Handler: index.lambda_handler
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.7
      Timeout: 60

  InitializeVPC:
    Type: Custom::InitFunction
    Properties:
      ServiceToken: !GetAtt InitFunction.Arn

# Create S3 Bucket to store single JSON file, and move file from staging account to bucket.
  UsersDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Join
        - '-'
        - - company-data
          - !Ref 'AWS::AccountId'

  CopyData:
    Type: Custom::CopyData
    Properties:
      ServiceToken: !GetAtt 'CopyFunction.Arn'
      DestBucket: !Ref 'UsersDataBucket'
      SourceBucket: das-c01-data-analytics-specialty
      APIGatewayURL: 'https://execute-api.amazonaws.com'
      Objects:
        - Labs/users_1_flat.json
    DependsOn:
      - UsersDataBucket

  CopyRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:*
                Resource:
                  - !Sub 'arn:aws:s3:::*'

  CopyFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from source bucket, modifies API Gateway Placeholder
        to URL from stack.
      Handler: lambda_function.handler
      Runtime: python3.7
      Role: !GetAtt 'CopyRole.Arn'
      Timeout: 240
      Code:
        S3Bucket: das-c01-data-analytics-specialty
        S3Key: Labs/programmatically-utilizing-data-from-s3/provisioning.zip
      FunctionName: users-index-provisioner

  LambdaS3Admin:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonS3FullAccess

# Smallest possible Redshift cluster, and role needed to utilize Redshift Spectrum
  UsersCluster: 
    Type: 'AWS::Redshift::Cluster'
    Properties:
      ClusterIdentifier: 'users-cluster'
      DBName: 'users'
      MasterUsername: 'users_admin'
      MasterUserPassword: Strongpass1
      NodeType: 'dc2.large'
      ClusterType: 'single-node'
      IamRoles:
        - !GetAtt 'SpectrumRole.Arn'
    DependsOn:
      - InitializeVPC

  SpectrumRole:
      Type: AWS::IAM::Role
      Properties:
        RoleName: SpectrumRole
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Principal:
                Service: redshift.amazonaws.com
              Action: sts:AssumeRole
        ManagedPolicyArns:
          - arn:aws:iam::aws:policy/AmazonS3FullAccess
          - arn:aws:iam::aws:policy/AWSGlueConsoleFullAccess

Outputs:
  pubIpAddress1:
    Description: Redshift Cluster Endpoint
    Value: !GetAtt 'UsersCluster.Endpoint.Address'

  pubIpAddress2:
    Description: Random Users data storage bucket
    Value: !Ref 'UsersDataBucket'

  pubIpAddress3:
    Description: Spectrum IAM Role
    Value: !GetAtt 'SpectrumRole.Arn'